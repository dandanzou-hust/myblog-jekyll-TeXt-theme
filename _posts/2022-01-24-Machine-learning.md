---
# 【文献阅读】【技术分享】【竞赛】

title:  "【机器学习】斯坦福21秋季：实用机器学习（李沐版本）"
date:   2022-01-20 12:00:00 +0800
key: machine-learning
categories: 机器学习
tag: "machine learning"

---

## 前言

李沐B站链接：[跟李沐学AI的个人空间_哔哩哔哩_bilibili](https://space.bilibili.com/1567748478/channel/collectiondetail?sid=28144)

这个课程是斯坦福大学2021年秋季新开的课程：实用机器学习。课程本身比较新，李沐大佬也做了中文版的课程，深入浅出，强烈建议跟随课程学习一遍。无论是像我这种工程师还是学生，都能有极大的收获。

## 1.1 课程介绍

机器学习工作流程：

![](https://zdd-1300938198.cos.ap-beijing.myqcloud.com//my-picture-bed/image-20220125103355933.png)

挑战：

- 表述问题：聚焦最有影响的工业问题转变为机器学习问题，如无人驾驶、无人超市。
- 数据：高质量数据，隐私问题。
- 训练模型：模型越来越复杂，数据越来越大。
- 应用模型：大量计算不适合实时场景。
- 监测：数据分布变化、公平问题。

规则：

- 领域专家：有业务经验，知道数据重要性、从哪里获取、找到有价值的地方。
- 数据科学家：数据挖掘、模型训练、上线。
- 机器学习专家：定制化机器学习模型。
- 软件开发工程师 (SDE)：开发、维护代码，模型训练，管理资源，模型部署。

技能提升：

![](https://zdd-1300938198.cos.ap-beijing.myqcloud.com//my-picture-bed/image-20220125103429313.png)

我理解的路线，先从开发出发，逐渐熟悉领域，转变为数据科学家。

## 1.2 数据获取

- 找数据
  
  - 常用数据集：MNIST、ImageNet、AudioSet、Kinetics、KITTI、Amazon Review、SQuAD、LibriSpeech
  
  - 常用途径：
    
    - Paperswithcodes Datasets: 提供了学术论文在数据集上的得分
    - Kaggle Datasets: 
    - Google Dataset search
    - 开源框架自带了部分数据集 tensorflow、huggingface。
    - 不同竞赛的数据集
    - Open Data on AWS:
    - Data lakes: 公司自己放数据的地方。
    
    学术数据集：干净、难度适中；选择受限、太简单、规模小；
    
    竞赛数据集：接近机器学习应用；还是简单、仅关注火热的话题；
    
    原始数据集：灵活；需要大量精力预处理；
  
  - 数据融合：多模态（不同来源的数据）融合

- 生成数据
  
  - GAN
  - 图像翻转、文本增强

## 1.3 网页数据抓取

- python selenium
- 云服务器可获取多个ip
- 注意法律风险

## 1.4 数据标注

- 半监督学习
- 众包
- 弱监督学习

半监督学习

​    自学习：

​        有标签数据 -> 训练模型 -> 预测无标签的数据  -> 数据合并   循环处理             

主动学习

​    模型筛选出难以确定的图片、人工标注

弱监督学习

​    设定多个规则，符合一定规则且数量超过阈值标为正。

## 2.1 探索性数据分析

技巧：

seaborn是matplotlib更高一层封装，有更多功能

pandas可以读取 zip 文件

```python
# 打印图片更高清
from IPython import display
display.set_matplotlib_formats('svg')
```

流程：

去空、缺值，转换数据类型、查看去除异常值。

## 2.2 数据清洗

错误数据：范围外、空值、类型错误

用各种数据分析工具，可视化数据分布，人为制定规则、模式来清洗数据。

## 2.3 数据变换

数值型数据：归一化、Z-score（标准化）、拉伸至±1区间内、取log。

图片数据：数据质量和数据大小的权衡。

视频数据：切分出感兴趣的片段。

文本数据：词根化、语法化、词元化。

## 2.4 特征工程

原因：机器学习需要处理固定长度的输入输出。

Tabular：

- 整数、浮点数：直接用就完了
- 类别型数据：one-hot编码
- 时序数据：展开成列，具体年月日不一定能挖掘出周末等信息，例如星期可以提取出来成一列。
- 特征组合：信息明确展开，利于机器学习。如：猫-公，狗-母。

Text：

- bag of words model：每个词做词元化，一个词是一个数字，没有时序信息。
- word embeddings 词嵌入：词转为向量，有语义信息。
- pre-trained language models 预训练模型 BERT GPT-3：transformer模型，自监督训练的模型。

Image/Video：

- 与训练好的深度学习模型，倒数第二层的输出作为图片抽取出的特征，放入如softmax层进行分类。

**表：特征抽取**

**文本、视频、图片、语音：深度学习抽取**

## 2.5 数据部分总结

一般流程：

1. 开始机器学习

2. 数据足够吗？
   
   1. 不够，找数据或生成数据

3. 提升数据、标签、模型
   
   1. label：半监督学习，自己标众包，启发式的规则抽取出标签。
   2. data：探索性数据分析，数据清洗，数据变换，特征工程。
   3. 更好的模型

挑战：

- 标号质量和数据量
- 数据质量
- 安全

## 3.1 机器学习总览

- 监督学习：
  - 自监督学习，标签由数据生成。word2vec，BERT
- 半监督学习
  - self-training
- 无监督学习
  - clustering、GAN
- 强化学习
  - 和环境进行交互，如机器人。

### 监督学习

基本部分：

- Model：输入预测输出。
- Loss：模型预测和真实值的差别。
- Objective：目标函数，最小化loss。
- Optimization：调整目标函数，学习模型参数。

监督学习模型种类：

- 决策树：用树做决策
- 线性模型：输入的线性组合
- 核方法：核函数计算特征的相似度
- 神经网络：前面的层学习特征，最后一层分类。

## 3.2 决策树

分类树和回归树

好处：

- 可解释性，为数不多的可解释的模型。
- 可以同时处理数值类和类别类的特征。

劣势：

- 不稳定，依赖数据，数据变了节点就变了。（集成学习来优化）
- 过于复杂的树会导致过拟合（剪枝）
- 不容易并行化计算。上线部署会慢。

随机森林

- 训练多个决策树以提升鲁棒性
- 随机性
  - bagging：训练集随机采样
  - 随机采样一定的特征

GBDT

- 梯度下降的理念，递进式的训练

树模型通常是我们能够用的第一选择，因为不需要特殊的调参。若有了一个还不错的结果，就可以继续优化数据，换用其他分类方法。

## 3.3 线性模型

线性回归——二分类

Softmax 回归——多分类

## 3.4 Mini-batch SGD

几乎是唯一求解方法（除了决策树）。

模型参数：$W$

核心： $W_{t+1}=W_t - 学习率*梯度$

## 3.5 MLP多层感知机

全连接层

## 3.6 CNN

卷积核，处理二维

## 3.7 RNN

时序，循环

## 4.1 评估指标

损失函数、耗时等

分类任务：accuracy、precision、recall、F1、AUC、ROC

Latency延时、ASN页面广告数、CTR点击率、ACP平均价格

## 4.2 过、欠拟合

训练误差：训练集上的误差

泛化误差：新数据集的误差

![](https://zdd-1300938198.cos.ap-beijing.myqcloud.com//my-picture-bed/20220715162629.png)

![](https://zdd-1300938198.cos.ap-beijing.myqcloud.com//my-picture-bed/20220715163155.png)

![](https://zdd-1300938198.cos.ap-beijing.myqcloud.com//my-picture-bed/20220715163655.png) 

## 4.3 模型验证

train  ：训练

val  ：可多次使用，但是用于测试，KFold

test：真正的仅使用一次，费数据。

## 5.1 方差、偏差

## 5.2 Bagging
